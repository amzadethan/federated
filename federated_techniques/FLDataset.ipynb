{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb9d0a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d794acfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IID function\n",
    "\n",
    "def mnistIID(dataset, num_users):\n",
    "    num_images = int(len(dataset) / num_users)\n",
    "    users_dict, indices = {}, [i for i in range(len(dataset))]\n",
    "    for i in range(num_users):\n",
    "        np.random.seed(i) \n",
    "        users_dict[i] = set(np.random.choice(indices, num_images, replace=False))\n",
    "        indices = list(set(indices) - users_dict[i])\n",
    "    return users_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b98180ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-IID function\n",
    "\n",
    "def mnistNonIID(dataset, num_users):\n",
    "    classes, images = 100, 600\n",
    "    classes_indx = [i for i in range(classes)]\n",
    "    indices = np.arrange(classes * images) \n",
    "    users_dict = { i:np.array([]) for i in range(num_users)}\n",
    "    unsorted_labels = dataset.train_labels.numpy()\n",
    "    \n",
    "    indices_unlabels = np.vstack(indices, unsorted_labels)\n",
    "    labels = indices_unlabels[:, indices_unlabels[1,:].argsort()]\n",
    "    indices = labels[0, :]\n",
    "    \n",
    "    for i in range(num_users):\n",
    "        temp = set(np.random.choice(classes_indx, 2, replace=False))\n",
    "        classes_indx = list(set(classes_indx) - temp)\n",
    "        \n",
    "        for i in temp:\n",
    "            users_dict[i] = np.concatenate(\n",
    "            (users_dict[i], indices[t*images:(t+1)*images]), axis = 0)\n",
    "    return users_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53ad1b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-IIDUnequal function\n",
    "\n",
    "def mnistNonIIDUnequal(dataset, num_users):\n",
    "    classes, images = 1200, 50\n",
    "    classes_indx = [i for i in range(classes)]\n",
    "    indices = np.arrange(classes * images)\n",
    "    users_dict = { i:np.array([]) for i in range(num_users)}\n",
    "    labels = dataset.train_labels.numpy()\n",
    "    \n",
    "    indices_labels = np.vstack(indices, labels)\n",
    "    indices_labels = indices_labels[:, indices_labels[1,:].argsort()]\n",
    "    indices = indices_labels[0, :]\n",
    "    \n",
    "    min_cls_per_client = 1\n",
    "    max_cls_per_client = 30\n",
    "    \n",
    "    random_selected_classes = np.random.tint(min_cls_per_client, max_cls_per_client+1, size=num_users)\n",
    "    random_selected_classes = np.around(random_selected_classes / sum(random_selected_classes) * classes)\n",
    "    random_selected_classes = random_selected_classes.astype(int)\n",
    "    \n",
    "    if sum(random_selected_classes)> classes:\n",
    "        \n",
    "        for i in range(num_users):\n",
    "            temp = set(np.random.choice(classes_indx, 1, replace=False))\n",
    "            classes_indx = list(set(classes_indx) - temp) \n",
    "            for t in temp:\n",
    "                users_dict[i] = np.concatenate((users_dict[i], indices[t*images:(t+1)*images]), axis = 0)\n",
    "            \n",
    "        random_selected_classes = random_selected_classes - 1\n",
    "        \n",
    "        for i in range(num_users):\n",
    "            if len(classes_indx) == 0:\n",
    "                continue\n",
    "            class_size = random_selected_classes[i]    \n",
    "            \n",
    "            if class_size > len(classes_indx):\n",
    "                class_size = len(class_indx)\n",
    "            \n",
    "            temp = set(np.random.choice(classes_indx, class_size, replace=False))\n",
    "            classes_indx = list(set(classes_indx) - temp)\n",
    "            for t in temp:\n",
    "                users_dict[i] = np.concatenate((users_dict[i], indices[t*images:(t+1)*images]), axis = 0)\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        for i in range(num_users):\n",
    "            class_size = random_selected_classes[i]\n",
    "            temp = set(np.random.choice(classes_indx, class_size, replace=False))\n",
    "            classes_indx = list(set(classes_indx) - temp)\n",
    "            for t in temp:\n",
    "                users_dict[i] = np.concatenate((users_dict[i], indices[t*images:(t+1)*images]), axis = 0)\n",
    "    \n",
    "        \n",
    "        if len(classes_indx) > 0:\n",
    "            class_size = len(classes_indx)\n",
    "            k = min(users_dict, key=lambda x: len(users_dict.get(x)))\n",
    "            temp = set(np.random.choice(classes_indx, class_size, replace=False))\n",
    "            classes_indx = list(set(classes_indx) - temp)\n",
    "            for t in temp:\n",
    "                users_dict[k] = np.concatenate((users_dict[i], indices[t*images:(t+1)*images]), axis = 0)\n",
    "    \n",
    "    return users_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18f0c057",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_dataset(num_users, iidtype):\n",
    "    \n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "    train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "\n",
    "    test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "    \n",
    "    train_group, test_group = None, None\n",
    "    if iidtype== 'iid':\n",
    "        train_group = mnistIID(train_dataset, num_users)\n",
    "        test_group = mnistIID(test_dataset, num_users)\n",
    "    elif iidtype== 'noniid':\n",
    "        train_group = mnistNonIID(train_dataset, num_users)\n",
    "        test_group = mnistNonIID(test_dataset, num_users)\n",
    "    else:\n",
    "        train_group = mnistNonIIDUnequal(train_dataset, num_users)\n",
    "        test_group = mnistNonIIDUnequal(test_dataset, num_users)\n",
    "    \n",
    "    return train_dataset, test_dataset, train_group, test_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08020317",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedDataset(Dataset):\n",
    "    def __init__(self, dataset, indx):\n",
    "        self.dataset = dataset\n",
    "        self.indx = [int(i) for i in indx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indx)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        images, label = self.dataset[self.indx[item]]\n",
    "        return torch.tensor(images).clone().detach(), torch.tensor(label).clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ac55628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getActualImages(dataset, indices, batch_size):\n",
    "    return DataLoader(FedDataset(dataset, indices), batch_size=batch_size, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
