{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231fcb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import syft as sy\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "from ipynb.fs.full.FLDataset import load_dataset, getActualImages\n",
    "from ipynb.fs.full.utils import averageModels, averageGradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1e7dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Argumens class\n",
    "\n",
    "class Arguments():\n",
    "    def __init__(self):\n",
    "        self.images = 60000\n",
    "        self.clients = 10\n",
    "        self.rounds = 2\n",
    "        self.epochs = 2\n",
    "        self.local_batches = 1\n",
    "        self.lr = 0.01\n",
    "        self.C = 0.9\n",
    "        self.drop_rate = 0.1\n",
    "        self.mu = 0.1\n",
    "        self.torch_seed = 0\n",
    "        self.log_interval = 10\n",
    "        self.iid = 'iid'\n",
    "        self.split_size = int(self.images / self.clients)\n",
    "        self.samples = self.split_size / self.images\n",
    "        self.use_cuda = False\n",
    "        self.save_model = False\n",
    "        \n",
    "args = Arguments()\n",
    "\n",
    "use_cuda = args.use_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069ab3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# virtual worker\n",
    "\n",
    "hook = sy.TorchHook(torch)\n",
    "clients = []\n",
    "\n",
    "for i in range(args.clients):\n",
    "    clients.append({'hook' : sy.VirtualWorker(hook, id=\"client{}\".format(i+1))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbbf541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "global_train, global_test, train_group, test_group = load_dataset(args.clients, args.iid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3561757",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inx, client in enumerate(clients):\n",
    "    client['trainset'] = getActualImages(global_train, list(train_group[inx])[:10], args.local_batches)\n",
    "    client['testset'] = getActualImages(global_test, list(test_group[inx]), args.local_batches)\n",
    "    client['samples'] = len(client['trainset']) / args.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1242025c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating test loader for global model\n",
    "# to test the global model\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,),(0.3081,))])\n",
    "global_test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "global_test_loader = DataLoader(global_test_dataset, batch_size=args.local_batches, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c1376e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net class\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5 ,1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5 ,1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5414d6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer for FedProx\n",
    "\n",
    "class FedProxOptim(optim.Optimizer):\n",
    "    def __init__(self, params, lr=args.lr, mu=args.mu):\n",
    "        defaults = dict(lr=lr, mu=mu)\n",
    "        super(FedProxOptim, self).__init__(params, defaults)\n",
    "    \n",
    "    def step(self, global_model=None, closure = None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "        for group in self.param_groups:\n",
    "            lr, mu = group['lr'], group['mu']\n",
    "            for p in zip(group['params'], list(global_model.parameters())):\n",
    "                if p[0].grad is None:\n",
    "                    continue\n",
    "                d_p = p[0].grad.data # local model grads\n",
    "                p[0].data.sub_(group['lr'], (d_p + mu * (p[0].data.clone() - p[1].data.clone())))\n",
    "                \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c723ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClientUpdate(args, device, client, global_model, rclients=False):\n",
    "    client['model'].train()\n",
    "    Epochs = args.epochs + 1\n",
    "    if rclients:\n",
    "        Epochs = np.random.randint(low=1, high=Epochs)\n",
    "        Epochs = 2\n",
    "\n",
    "    for epoch in range(1, Epochs):\n",
    "        for batch_idx, (data, target) in enumerate(client['trainset']):\n",
    "            data = data.send(client['hook'])\n",
    "            target = target.send(client['hook'])\n",
    "            client['model'].send(data.location)\n",
    "            \n",
    "            data, target = data.to(device), target.to(device)\n",
    "            client['optim'].zero_grad()\n",
    "            output = client['model'](data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            client['optim'].step(global_model.send(client['hook']))\n",
    "            client['model'].get() \n",
    "            global_model.get()\n",
    "\n",
    "            if batch_idx % args.log_interval == 0:\n",
    "                loss = loss.get() \n",
    "                print('Model {} Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    client['hook'].id,\n",
    "                    epoch, batch_idx * args.local_batches, len(client['trainset']) * args.local_batches, \n",
    "                    100. * batch_idx / len(client['trainset']), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ad5c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, model, device, test_loader, name):\n",
    "    model.eval()   \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss for {} model: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        name, test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa73aedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(args.torch_seed) \n",
    "global_model = Net().to(device)\n",
    "\n",
    "for client in clients:\n",
    "    torch.manual_seed(args.torch_seed)\n",
    "    client['model'] = Net().to(device)\n",
    "    client['optim'] = FedProxOptim(client['model'].parameters(), lr=args.lr, mu=args.mu)\n",
    "    \n",
    "for fed_round in range(args.rounds):\n",
    "    \n",
    "    \n",
    "    m = int(max(args.C * args.clients, 1))\n",
    "    np.random.seed(fed_round)\n",
    "    selected_clients_inds = np.random.choice(range(len(clients)), m, replace=False)\n",
    "    selected_clients = [clients[i] for i in selected_clients_inds]\n",
    "    \n",
    "    # Active Clients\n",
    "    \n",
    "    active_clients_inds = np.random.choice(selected_clients_inds, int((1-args.drop_rate) * m), replace=False)\n",
    "    active_clients = [clients[i] for i in active_clients_inds]\n",
    "    \n",
    "    # rest clients, which were dropped\n",
    "    \n",
    "    rest_clients_inds = np.setdiff1d(selected_clients_inds, active_clients_inds)\n",
    "    rest_clients = [clients[i] for i in rest_clients_inds]\n",
    "    \n",
    "    # train function for active clients\n",
    "    for client in active_clients:\n",
    "        ClientUpdate(args, device, client, global_model)\n",
    "        \n",
    "    # train function for rest of the clients with less epochs\n",
    "    for client in rest_clients:\n",
    "        ClientUpdate(args, device, client, global_model, True)\n",
    "        \n",
    "    global_model = averageModels(global_model, selected_clients)\n",
    "    \n",
    "    test(args, global_model, device, global_test_loader, 'Global')\n",
    "    \n",
    "    # share the global model with the local clients\n",
    "    for client in clients:\n",
    "        client['model'].load_state_dict(global_model.state_dict())\n",
    "        \n",
    "# after finishing all the epochs, if we want to save the model\n",
    "\n",
    "if (args.save_model):\n",
    "    torch.save(global_model.state_dict(), \"FedProx.pt\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
