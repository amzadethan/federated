{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d3684af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as datasest will load for us a chunk of data not a tuple\n",
    "# we need to import DataLoader and Dataset form torch.utils.data \n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0bf1253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will create a IID function\n",
    "# which will take our dataset and num_users for calculating num_images which is \n",
    "# the number of images each paritipating client will have\n",
    "# and this function will take each client at a time and parse\n",
    "# random number of indices to its own list\n",
    "\n",
    "def mnistIID(dataset, num_users):\n",
    "    num_images = int(len(dataset) / num_users) # formula for calculating each participating clients image number\n",
    "    users_dict, indices = {}, [i for i in range(len(dataset))] # dictionary type data structure so that key->client number, value->list of total indices of the dataset\n",
    "    for i in range(num_users):\n",
    "        np.random.seed(i) # so that everytime the random function is run, as we are evaluating, we need it to choose which it chose previously the random number\n",
    "        users_dict[i] = set(np.random.choice(indices, num_images, replace=False)) #set-> by default will drop the repeated items, numpy.random.choice will choose a number from passed list, num_images for how many numbers it needs to choose from the list, replace=False as we dont want the repeated indice number\n",
    "        indices = list(set(indices) - users_dict[i]) # to drop the indices chose on the previous line\n",
    "    return users_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21efe90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will create a non-IID function\n",
    "# Note- we have decided to give equally 2 classes each time for each client\n",
    "# First we need to select the number of classes\n",
    "# And based on this number,we are going to distribute\n",
    "# the dataset and the number of images we wat to give\n",
    "# each client from each class\n",
    "# then we need to create classes indices list\n",
    "# after that, we need to create the indices\n",
    "# after that, we need to the labels from the dataset\n",
    "# these labels are unsorted as we need to sort the\n",
    "# labels later\n",
    "# then, we need to create a list of\n",
    "# indices with unsorted labels\n",
    "# then we need to sort the new unsorted labels\n",
    "# then we need to update the indices list for current sorted\n",
    "# then, we need to iterate over all the clients and \n",
    "# each client is going to select random indices from\n",
    "# the classes, and for that we will use \n",
    "# numpy.random.choice\n",
    "# and once a client's random number is chosen\n",
    "# we need to remove those indices from classes_indx list\n",
    "# and then, we need to update our users_dict with the images\n",
    "# \n",
    "\n",
    "def mnistNonIID(dataset, num_users):\n",
    "    classes, images = 100, 600\n",
    "    classes_indx = [i for i in range(classes)]\n",
    "    indices = np.arrange(classes * images) # basically the length of the training dataset\n",
    "    users_dict = { i:np.array([]) for i in range(num_users)}\n",
    "    unsorted_labels = dataset.train_labels.numpy() # we need to convert them into numpy as we need to stack them with their specific data with numpy vstack\n",
    "    \n",
    "    indices_unlabels = np.vstack(indices, unsorted_labels)\n",
    "    labels = indices_unlabels[:, indices_unlabels[1,:].argsort()]\n",
    "    indices = labels[0, :]\n",
    "    \n",
    "    # so we need to iterate over num_users\n",
    "    # we need a temp variable to hold the indices of the classes\n",
    "\n",
    "    \n",
    "    \n",
    "    for i in range(num_users):\n",
    "        temp = set(np.random.choice(classes_indx, 2, replace=False)) # 2 = the number of classes we want to give for each clients at a time equally\n",
    "        classes_indx = list(set(classes_indx) - temp)\n",
    "        \n",
    "        for i in temp:\n",
    "            users_dict[i] = np.concatenate(\n",
    "            (users_dict[i], indices[t*images:(t+1)*images]), axis = 0)\n",
    "    return users_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55cac3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will create a non-IIDUnequal function\n",
    "# Note- This function will give unequal number of classes to each clients\n",
    "# First we need to select the number of classes\n",
    "# And based on this number,we are going to distribute\n",
    "# the dataset and the number of images we wat to give\n",
    "# each client from each class\n",
    "# then we need to create classes indices list\n",
    "# after that, we need to create the indices\n",
    "# after that, we need to the labels from the dataset\n",
    "# these labels are unsorted as we need to sort the\n",
    "# labels later\n",
    "# then, we need to create a list of\n",
    "# indices with unsorted labels\n",
    "# then we need to sort the new unsorted labels\n",
    "# then we need to update the indices list for current sorted\n",
    "# then, we need to iterate over all the clients and \n",
    "# each client is going to select random indices from\n",
    "# the classes, and for that we will use \n",
    "# numpy.random.choice\n",
    "# and once a client's random number is chosen\n",
    "# we need to remove those indices from classes_indx list\n",
    "# and then, we need to update our users_dict with the images\n",
    "# \n",
    "\n",
    "def mnistNonIIDUnequal(dataset, num_users):\n",
    "    classes, images = 1200, 50\n",
    "    classes_indx = [i for i in range(classes)]\n",
    "    indices = np.arrange(classes * images) # basically the length of the training dataset\n",
    "    users_dict = { i:np.array([]) for i in range(num_users)}\n",
    "    labels = dataset.train_labels.numpy() # we need to convert them into numpy as we need to stack them with their specific data with numpy vstack\n",
    "    \n",
    "    indices_labels = np.vstack(indices, labels)\n",
    "    indices_labels = indices_labels[:, indices_labels[1,:].argsort()]\n",
    "    indices = indices_labels[0, :]\n",
    "    \n",
    "    # now we need to set minimum number of classes for each user \n",
    "    # then, we need to set maximum number of classes for each user\n",
    "    # then, we need to calculate from random generated numbers to get the probability of each class's chosen number\n",
    "    \n",
    "    min_cls_per_client = 1\n",
    "    max_cls_per_client = 30\n",
    "    \n",
    "    random_selected_classes = np.random.tint(min_cls_per_client, max_cls_per_client+1, size=num_users)\n",
    "    random_selected_classes = np.around(random_selected_classes / sum(random_selected_classes) * classes)\n",
    "    random_selected_classes = random_selected_classes.astype(int)\n",
    "    \n",
    "    if sum(random_selected_classes)> classes:\n",
    "        \n",
    "        for i in range(num_users):\n",
    "            temp = set(np.random.choice(classes_indx, 1, replace=False)) # for giving each users at least one class\n",
    "            classes_indx = list(set(classes_indx) - temp) # dropping the at least one class chosen for one user from overall classes\n",
    "            for t in temp:\n",
    "                users_dict[i] = np.concatenate((users_dict[i], indices[t*images:(t+1)*images]), axis = 0)\n",
    "            \n",
    "        random_selected_classes = random_selected_classes - 1\n",
    "        \n",
    "        for i in range(num_users):\n",
    "            if len(classes_indx) == 0:\n",
    "                continue\n",
    "            class_size = random_selected_classes[i]    \n",
    "            \n",
    "            if class_size > len(classes_indx):\n",
    "                class_size = len(class_indx)\n",
    "            \n",
    "            temp = set(np.random.choice(classes_indx, class_size, replace=False))\n",
    "            classes_indx = list(set(classes_indx) - temp)\n",
    "            for t in temp:\n",
    "                users_dict[i] = np.concatenate((users_dict[i], indices[t*images:(t+1)*images]), axis = 0)\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        for i in range(num_users):\n",
    "            class_size = random_selected_classes[i]\n",
    "            temp = set(np.random.choice(classes_indx, class_size, replace=False))\n",
    "            classes_indx = list(set(classes_indx) - temp)\n",
    "            for t in temp:\n",
    "                users_dict[i] = np.concatenate((users_dict[i], indices[t*images:(t+1)*images]), axis = 0)\n",
    "    \n",
    "        \n",
    "        if len(classes_indx) > 0:\n",
    "            class_size = len(classes_indx)\n",
    "            k = min(users_dict, key=lambda x: len(users_dict.get(x))) # getting the client who has got the least number of classes\n",
    "            temp = set(np.random.choice(classes_indx, class_size, replace=False))\n",
    "            classes_indx = list(set(classes_indx) - temp)\n",
    "            for t in temp:\n",
    "                users_dict[k] = np.concatenate((users_dict[i], indices[t*images:(t+1)*images]), axis = 0)\n",
    "    \n",
    "    return users_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ab8df48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# first we need to load the image data\n",
    "# so first we will create a transform\n",
    "# then we will create the training dataset\n",
    "# then, test dataset --Note: for test dataset we have to put train=False in the argument, so that pytorch will know that it will be used for test dataset\n",
    "#\n",
    "\n",
    "def load_dataset(num_users, iidtype):\n",
    "# we will load the data\n",
    "\n",
    "    # first we need to create a transform\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]) # this nomralization will only work for this MNIST Dataset\n",
    "\n",
    "    # we will download the dataset\n",
    "    train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "\n",
    "    # we weill need a test dataset\n",
    "    test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "    \n",
    "    train_group, test_group = None, None\n",
    "    if iidtype== 'iid':\n",
    "        train_group = mnistIID(train_dataset, num_users)\n",
    "        test_group = mnistIID(test_dataset, num_users)\n",
    "    elif iidtype== 'noniid':\n",
    "        train_group = mnistNonIID(train_dataset, num_users)\n",
    "        test_group = mnistNonIID(test_dataset, num_users)\n",
    "    else:\n",
    "        train_group = mnistNonIIDUnequal(train_dataset, num_users)\n",
    "        test_group = mnistNonIIDUnequal(test_dataset, num_users)\n",
    "    \n",
    "    return train_dataset, test_dataset, train_group, test_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18dad5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we need to pass a list of numbers and we \n",
    "# want to fetch the actual images and targets\n",
    "# we need to create a class so it inherits all the features\n",
    "# and all the functions from the dataset\n",
    "\n",
    "class FedDataset(Dataset):\n",
    "    def __init__(self, dataset, indx):\n",
    "        self.dataset = dataset\n",
    "        self.indx = [int(i) for i in indx]\n",
    "     \n",
    "    # we need to change len\n",
    "    # as we dont want it to return the actal size of the dataset\n",
    "    # we want it to return the length of our indices for\n",
    "    # that specific client\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indx)\n",
    "    \n",
    "    # we need to define a function, which will get the item\n",
    "    # thats going to return the images and labels where each image\n",
    "    # and label is equal\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        images, label = self.dataset[self.indx[item]]\n",
    "        return torch.tensor(images).clone().detach(), torch.tensor(label).clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8b356f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this funtion will take indices and going to parse the actual image at target\n",
    "# in DataLoader, the dataset that we need to pass is gonna have to be an actual dataset like the train_dataset or the test_dataset we created\n",
    "\n",
    "def getActualImages(dataset, indices, batch_size):\n",
    "    return DataLoader(FedDataset(dataset, indices), batch_size=batch_size, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
